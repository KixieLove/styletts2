{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d3b37f",
   "metadata": {},
   "source": [
    "# StyleTTS2 Training Progress Monitor\n",
    "\n",
    "This notebook helps you visualize and understand your StyleTTS2 training progress. You'll see loss curves, trend analysis, and guidance on what healthy training looks like.\n",
    "\n",
    "## Key Questions This Answers:\n",
    "- Is my model learning or is loss stuck?\n",
    "- Am I overfitting (model memorizing instead of learning)?\n",
    "- Are all loss components being trained?\n",
    "- What does \"good training\" look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a15f52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ae6bcd",
   "metadata": {},
   "source": [
    "## Section 1: Load Training Data from Logs\n",
    "\n",
    "We'll read your training log file and extract all loss metrics for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Change these paths to match your setup\n",
    "LOG_DIR = r\"d:\\Tesis\\StyleTTS2\\logs\\angelina_es\"\n",
    "LOG_FILE = Path(LOG_DIR) / \"train.log\"\n",
    "\n",
    "print(f\"Loading training logs from: {LOG_FILE}\")\n",
    "print(f\"Log file exists: {LOG_FILE.exists()}\")\n",
    "\n",
    "# Parse the training log\n",
    "def parse_training_log(log_path):\n",
    "    \"\"\"\n",
    "    Parse training log and extract metrics for each step.\n",
    "    Returns a pandas DataFrame with all loss components.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'epoch': [],\n",
    "        'step': [],\n",
    "        'total_steps': [],\n",
    "        'mel_loss': [],\n",
    "        'gen_loss': [],\n",
    "        'disc_loss': [],\n",
    "        'mono_loss': [],\n",
    "        's2s_loss': [],\n",
    "        'slm_loss': []\n",
    "    }\n",
    "    \n",
    "    # Pattern: Epoch [1/200], Step [10/905], Mel Loss: 1.43579, Gen Loss: 0.00000, ...\n",
    "    pattern = r'Epoch \\[(\\d+)/(\\d+)\\], Step \\[(\\d+)/(\\d+)\\], Mel Loss: ([\\d.]+), Gen Loss: ([\\d.]+), Disc Loss: ([\\d.]+), Mono Loss: ([\\d.]+), S2S Loss: ([\\d.]+), SLM Loss: ([\\d.]+)'\n",
    "    \n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            match = re.search(pattern, line)\n",
    "            if match:\n",
    "                epoch, total_epochs, step, total_steps, mel, gen, disc, mono, s2s, slm = match.groups()\n",
    "                \n",
    "                data['epoch'].append(int(epoch))\n",
    "                data['step'].append(int(step))\n",
    "                data['total_steps'].append(int(total_steps))\n",
    "                data['mel_loss'].append(float(mel))\n",
    "                data['gen_loss'].append(float(gen))\n",
    "                data['disc_loss'].append(float(disc))\n",
    "                data['mono_loss'].append(float(mono))\n",
    "                data['s2s_loss'].append(float(s2s))\n",
    "                data['slm_loss'].append(float(slm))\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df = parse_training_log(LOG_FILE)\n",
    "\n",
    "print(f\"\\n‚úì Successfully loaded {len(df)} training steps\")\n",
    "print(f\"Epochs covered: {df['epoch'].min()} to {df['epoch'].max()}\")\n",
    "print(f\"Latest epoch: {df['epoch'].iloc[-1]}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ac136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate epoch-level statistics (average loss per epoch)\n",
    "epoch_stats = df.groupby('epoch')[['mel_loss', 'gen_loss', 'disc_loss', 'mono_loss', 's2s_loss', 'slm_loss']].agg(['mean', 'min', 'max', 'std'])\n",
    "\n",
    "print(\"Epoch-level statistics (first 10 epochs):\")\n",
    "print(epoch_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f0682",
   "metadata": {},
   "source": [
    "## Section 2: Main Loss Trend (Per Epoch)\n",
    "\n",
    "The most important metric: **Mel Loss**. This is your reconstruction loss - lower is better. In StyleTTS2:\n",
    "- **Stage 1** (first ~30 epochs): Only Mel Loss is active. You should see it **decrease smoothly**.\n",
    "- **Stage 2** (after ~30 epochs): Other losses activate (Gen Loss, Disc Loss, etc.). Mel Loss might increase slightly, which is normal.\n",
    "\n",
    "Watch for:\n",
    "- ‚úì **Good**: Steady decrease in early training\n",
    "- ‚úó **Bad**: Loss stuck/flat for many epochs\n",
    "- ‚úó **Bad**: Sudden spikes (might indicate NaN or training issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e336dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Group by epoch and compute mean\n",
    "epoch_mel = df.groupby('epoch')['mel_loss'].mean()\n",
    "\n",
    "ax.plot(epoch_mel.index, epoch_mel.values, linewidth=2.5, label='Mel Loss', color='#1f77b4', marker='o', markersize=3)\n",
    "ax.fill_between(epoch_mel.index, epoch_mel.values, alpha=0.2, color='#1f77b4')\n",
    "\n",
    "ax.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Mel Loss', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Training Progress: Mel Loss per Epoch\\n(Main Reconstruction Loss)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "# Add annotations for first and last values\n",
    "first_loss = epoch_mel.iloc[0]\n",
    "last_loss = epoch_mel.iloc[-1]\n",
    "improvement = (first_loss - last_loss) / first_loss * 100\n",
    "\n",
    "ax.text(0.02, 0.98, f'First: {first_loss:.4f}\\nLast: {last_loss:.4f}\\nImprovement: {improvement:.1f}%', \n",
    "        transform=ax.transAxes, verticalalignment='top', \n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8), fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Mel Loss Summary:\")\n",
    "print(f\"   Starting loss: {first_loss:.6f}\")\n",
    "print(f\"   Current loss: {last_loss:.6f}\")\n",
    "print(f\"   Improvement: {improvement:.2f}%\")\n",
    "print(f\"   Trend: {'‚úì IMPROVING' if improvement > 5 else '‚ö† FLAT' if improvement < 1 else '‚úì IMPROVING'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3183e341",
   "metadata": {},
   "source": [
    "## Section 3: All Loss Components Across Training\n",
    "\n",
    "StyleTTS2 uses multiple loss components. Let's see how each one changes:\n",
    "- **Mel Loss**: Reconstruction (should decrease)\n",
    "- **Gen Loss**: Generator adversarial loss\n",
    "- **Disc Loss**: Discriminator loss\n",
    "- **Mono Loss**: Monotonic alignment loss\n",
    "- **S2S Loss**: Sequence-to-sequence loss\n",
    "- **SLM Loss**: Speech Language Model loss\n",
    "\n",
    "**Note**: Losses that are 0.0 mean they haven't been activated yet (depends on training stage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04367df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "loss_columns = ['mel_loss', 'gen_loss', 'disc_loss', 'mono_loss', 's2s_loss', 'slm_loss']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "\n",
    "for idx, (col, color) in enumerate(zip(loss_columns, colors)):\n",
    "    epoch_loss = df.groupby('epoch')[col].mean()\n",
    "    \n",
    "    axes[idx].plot(epoch_loss.index, epoch_loss.values, linewidth=2, color=color, marker='o', markersize=3)\n",
    "    axes[idx].fill_between(epoch_loss.index, epoch_loss.values, alpha=0.2, color=color)\n",
    "    axes[idx].set_title(col.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Epoch', fontsize=10)\n",
    "    axes[idx].set_ylabel('Loss', fontsize=10)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add text with current status\n",
    "    has_data = (epoch_loss > 0).any()\n",
    "    latest = epoch_loss.iloc[-1]\n",
    "    status_text = f\"Active\\n(Latest: {latest:.6f})\" if has_data and latest > 0 else \"Not Active\\n(0.0)\"\n",
    "    axes[idx].text(0.98, 0.97, status_text, transform=axes[idx].transAxes, \n",
    "                   verticalalignment='top', horizontalalignment='right',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7), fontsize=9)\n",
    "\n",
    "plt.suptitle('All Loss Components During Training', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\nüìà Loss Component Status:\\n\")\n",
    "for col in loss_columns:\n",
    "    epoch_loss = df.groupby('epoch')[col].mean()\n",
    "    has_data = (epoch_loss > 0).any()\n",
    "    if has_data:\n",
    "        first_nonzero = epoch_loss[epoch_loss > 0].iloc[0] if (epoch_loss > 0).any() else np.nan\n",
    "        first_epoch = epoch_loss[epoch_loss > 0].index[0] if (epoch_loss > 0).any() else 0\n",
    "        current = epoch_loss.iloc[-1]\n",
    "        print(f\"  {col.upper():12} ‚Üí Started at epoch {first_epoch:3d}, Current: {current:.6f}\")\n",
    "    else:\n",
    "        print(f\"  {col.upper():12} ‚Üí Not yet activated (still 0.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa8fdd",
   "metadata": {},
   "source": [
    "## Section 4: Training Stability & Variance\n",
    "\n",
    "Stable training = loss stays relatively smooth with small changes between steps. Large spikes or noise indicate potential issues.\n",
    "\n",
    "This chart shows **rolling average** (smooths out noise) and **variance** to see if training is stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa41770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling statistics for mel_loss (the main metric)\n",
    "window_size = 50  # smooth over 50 steps\n",
    "\n",
    "df['mel_loss_rolling_mean'] = df['mel_loss'].rolling(window=window_size, min_periods=1).mean()\n",
    "df['mel_loss_rolling_std'] = df['mel_loss'].rolling(window=window_size, min_periods=1).std()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Loss with rolling average\n",
    "ax1.plot(df.index, df['mel_loss'], alpha=0.3, label='Raw Mel Loss', color='lightblue', linewidth=0.8)\n",
    "ax1.plot(df.index, df['mel_loss_rolling_mean'], label=f'Rolling Mean (window={window_size})', \n",
    "         color='darkblue', linewidth=2.5)\n",
    "ax1.fill_between(df.index, \n",
    "                  df['mel_loss_rolling_mean'] - df['mel_loss_rolling_std'],\n",
    "                  df['mel_loss_rolling_mean'] + df['mel_loss_rolling_std'],\n",
    "                  alpha=0.2, color='darkblue', label='¬±1 Std Dev')\n",
    "ax1.set_ylabel('Mel Loss', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Training Loss: Raw vs Smoothed (Rolling Average)', fontsize=12, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Standard deviation (variance indicator)\n",
    "ax2.plot(df.index, df['mel_loss_rolling_std'], color='#d62728', linewidth=2)\n",
    "ax2.fill_between(df.index, df['mel_loss_rolling_std'], alpha=0.3, color='#d62728')\n",
    "ax2.set_xlabel('Training Step', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Standard Deviation', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Training Stability: Loss Variance (Lower = More Stable)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(\"\\nüîç Stability Analysis:\\n\")\n",
    "avg_std = df['mel_loss_rolling_std'].mean()\n",
    "recent_std = df['mel_loss_rolling_std'].iloc[-100:].mean() if len(df) > 100 else df['mel_loss_rolling_std'].mean()\n",
    "\n",
    "print(f\"  Average variance (all steps): {avg_std:.6f}\")\n",
    "print(f\"  Recent variance (last 100 steps): {recent_std:.6f}\")\n",
    "print(f\"  Stability trend: {'‚úì STABLE' if recent_std < avg_std else '‚ö† BECOMING LESS STABLE' if recent_std > avg_std * 1.5 else '‚úì ACCEPTABLE'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdbaf1",
   "metadata": {},
   "source": [
    "## Section 5: Training Health Diagnosis\n",
    "\n",
    "Here's a checklist to help you understand if training is going well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_training(df, epoch_stats):\n",
    "    \"\"\"\n",
    "    Analyze training and provide health diagnosis with actionable feedback.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üî¨ TRAINING HEALTH DIAGNOSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 1. Loss trend\n",
    "    epoch_mel = df.groupby('epoch')['mel_loss'].mean()\n",
    "    first_20 = epoch_mel.iloc[:min(20, len(epoch_mel))].mean() if len(epoch_mel) > 0 else 0\n",
    "    last_20 = epoch_mel.iloc[max(0, len(epoch_mel)-20):].mean() if len(epoch_mel) > 0 else 0\n",
    "    improvement = (first_20 - last_20) / first_20 * 100 if first_20 > 0 else 0\n",
    "    \n",
    "    print(\"\\n‚úì CHECK 1: Loss Decreasing?\")\n",
    "    if improvement > 5:\n",
    "        print(f\"  ‚úÖ YES - Loss improved by {improvement:.1f}%\")\n",
    "        print(f\"     First 20 epochs avg: {first_20:.6f}\")\n",
    "        print(f\"     Last 20 epochs avg: {last_20:.6f}\")\n",
    "        print(f\"     ‚Üí GOOD: Model is learning!\")\n",
    "    elif improvement > 0:\n",
    "        print(f\"  ‚ö†Ô∏è  SLIGHT - Loss improved by only {improvement:.1f}%\")\n",
    "        print(f\"     ‚Üí CAUTION: Very slow progress. Check learning rate.\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå NO - Loss increased or flat by {-improvement:.1f}%\")\n",
    "        print(f\"     ‚Üí BAD: Model is not learning. Check:\")\n",
    "        print(f\"        - Learning rate might be too high\")\n",
    "        print(f\"        - Data quality/preprocessing\")\n",
    "        print(f\"        - Model architecture\")\n",
    "    \n",
    "    # 2. Stability check\n",
    "    recent_loss = df['mel_loss'].iloc[-100:] if len(df) > 100 else df['mel_loss']\n",
    "    loss_std = recent_loss.std()\n",
    "    loss_mean = recent_loss.mean()\n",
    "    noise_ratio = (loss_std / loss_mean) * 100 if loss_mean > 0 else 0\n",
    "    \n",
    "    print(\"\\n‚úì CHECK 2: Training Stable?\")\n",
    "    if noise_ratio < 10:\n",
    "        print(f\"  ‚úÖ YES - Noise ratio: {noise_ratio:.1f}% (< 10%)\")\n",
    "        print(f\"     ‚Üí GOOD: Smooth, consistent training\")\n",
    "    elif noise_ratio < 20:\n",
    "        print(f\"  ‚ö†Ô∏è  MODERATE - Noise ratio: {noise_ratio:.1f}% (10-20%)\")\n",
    "        print(f\"     ‚Üí ACCEPTABLE: Some fluctuation is normal\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå HIGH VARIANCE - Noise ratio: {noise_ratio:.1f}% (> 20%)\")\n",
    "        print(f\"     ‚Üí CAUTION: Very noisy training. Consider:\")\n",
    "        print(f\"        - Reducing batch size\")\n",
    "        print(f\"        - Lowering learning rate\")\n",
    "        print(f\"        - Checking for gradient clipping\")\n",
    "    \n",
    "    # 3. Loss spike detection\n",
    "    recent_50 = df['mel_loss'].iloc[-50:] if len(df) > 50 else df['mel_loss']\n",
    "    max_recent = recent_50.max()\n",
    "    min_recent = recent_50.min()\n",
    "    spike_ratio = (max_recent - min_recent) / min_recent * 100 if min_recent > 0 else 0\n",
    "    \n",
    "    print(\"\\n‚úì CHECK 3: Sudden Spikes?\")\n",
    "    if spike_ratio < 30:\n",
    "        print(f\"  ‚úÖ NO - Max spike in recent steps: {spike_ratio:.1f}%\")\n",
    "        print(f\"     ‚Üí GOOD: No NaN/Inf issues detected\")\n",
    "    elif spike_ratio < 100:\n",
    "        print(f\"  ‚ö†Ô∏è  MINOR - Spike ratio: {spike_ratio:.1f}%\")\n",
    "        print(f\"     ‚Üí ACCEPTABLE: Small fluctuations are normal\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå MAJOR SPIKES - Spike ratio: {spike_ratio:.1f}%\")\n",
    "        print(f\"     ‚Üí WARNING: Large sudden changes detected\")\n",
    "        print(f\"     Max: {max_recent:.6f}, Min: {min_recent:.6f}\")\n",
    "    \n",
    "    # 4. Training stage\n",
    "    gen_loss = df.groupby('epoch')['gen_loss'].mean()\n",
    "    gen_active = (gen_loss > 0).any()\n",
    "    mel_epoch = epoch_mel.index.max()\n",
    "    \n",
    "    print(\"\\n‚úì CHECK 4: Training Stage?\")\n",
    "    if gen_active:\n",
    "        gen_active_epoch = gen_loss[gen_loss > 0].index.min()\n",
    "        print(f\"  ‚ÑπÔ∏è  STAGE 2 ACTIVE\")\n",
    "        print(f\"     Gen/Disc losses activated at epoch {gen_active_epoch}\")\n",
    "        print(f\"     Current epoch: {mel_epoch}\")\n",
    "        print(f\"     ‚Üí Training adversarial objectives alongside reconstruction\")\n",
    "    else:\n",
    "        print(f\"  ‚ÑπÔ∏è  STAGE 1 ACTIVE\")\n",
    "        print(f\"     Only Mel loss is active (no adversarial training yet)\")\n",
    "        print(f\"     Current epoch: {mel_epoch}\")\n",
    "        print(f\"     ‚Üí Normal early-stage training\")\n",
    "    \n",
    "    # 5. Overall assessment\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üìä OVERALL ASSESSMENT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    score = 0\n",
    "    if improvement > 5: score += 1\n",
    "    if noise_ratio < 20: score += 1\n",
    "    if spike_ratio < 100: score += 1\n",
    "    \n",
    "    if score >= 2.5:\n",
    "        print(\"‚úÖ TRAINING IS HEALTHY - Keep going!\")\n",
    "        print(\"   Your model is learning well. Continue monitoring.\")\n",
    "    elif score >= 1.5:\n",
    "        print(\"‚ö†Ô∏è  TRAINING IS ACCEPTABLE - But watch for issues\")\n",
    "        print(\"   Training is progressing but has some concerns.\")\n",
    "    else:\n",
    "        print(\"‚ùå TRAINING HAS ISSUES - Review settings\")\n",
    "        print(\"   Multiple problems detected. Consider changing hyperparameters.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Run diagnosis\n",
    "diagnose_training(df, epoch_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d025f9c",
   "metadata": {},
   "source": [
    "## Section 6: Understanding Training Patterns\n",
    "\n",
    "### What does \"Good Training\" look like?\n",
    "\n",
    "**‚úÖ Healthy Training Pattern:**\n",
    "- **Mel Loss**: Decreases in early epochs (stage 1), then may increase slightly when other losses activate (stage 2) - this is expected\n",
    "- **Smooth curve**: No sudden spikes or erratic behavior\n",
    "- **Consistent improvement**: Week-to-week you see lower average losses\n",
    "- **All losses active**: In stage 2, you should see Gen/Disc/Mono/S2S/SLM all > 0\n",
    "\n",
    "**‚ö†Ô∏è Warning Signs:**\n",
    "- **Flat loss**: No improvement for many epochs\n",
    "- **Increasing loss**: Getting worse instead of better\n",
    "- **Sudden spikes**: Loss suddenly jumps (could indicate numerical issues)\n",
    "- **High variance**: Loss jumps around too much each step\n",
    "- **Loss stays at 0**: Some losses not activating when they should be\n",
    "\n",
    "### What's Normal?\n",
    "\n",
    "1. **Stage 1 (first ~20-30 epochs)**: Only Mel Loss active - should see steady decrease\n",
    "2. **Transition (epochs 30-40)**: Other losses activate. Mel Loss might increase slightly - THIS IS OK\n",
    "3. **Stage 2 (epoch 40+)**: Multiple losses competing. Training becomes more complex but should stabilize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7eaedf",
   "metadata": {},
   "source": [
    "## Section 7: Detailed Epoch Comparison\n",
    "\n",
    "Compare how losses change from one epoch to the next. This helps spot when things change (like when stage 2 starts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577eed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed epoch summary table\n",
    "epoch_summary = df.groupby('epoch').agg({\n",
    "    'mel_loss': ['mean', 'min', 'max'],\n",
    "    'gen_loss': 'mean',\n",
    "    'disc_loss': 'mean',\n",
    "    'mono_loss': 'mean',\n",
    "    's2s_loss': 'mean',\n",
    "    'slm_loss': 'mean'\n",
    "}).round(6)\n",
    "\n",
    "# Flatten column names\n",
    "epoch_summary.columns = ['_'.join(col).strip() for col in epoch_summary.columns]\n",
    "epoch_summary.columns = ['Mel_Avg', 'Mel_Min', 'Mel_Max', 'Gen', 'Disc', 'Mono', 'S2S', 'SLM']\n",
    "\n",
    "# Show recent epochs\n",
    "print(\"\\nüìã Recent Epochs Summary (last 15 epochs):\\n\")\n",
    "print(epoch_summary.tail(15).to_string())\n",
    "\n",
    "# Identify when stage 2 starts (when non-mel losses activate)\n",
    "stage2_epoch = None\n",
    "for loss_col in ['gen_loss', 'disc_loss', 'mono_loss', 's2s_loss', 'slm_loss']:\n",
    "    active_epochs = df[df[loss_col] > 0]['epoch'].unique()\n",
    "    if len(active_epochs) > 0:\n",
    "        first_active = active_epochs.min()\n",
    "        if stage2_epoch is None or first_active < stage2_epoch:\n",
    "            stage2_epoch = first_active\n",
    "\n",
    "print(f\"\\n\\nüìå Training Stages Detected:\")\n",
    "if stage2_epoch:\n",
    "    print(f\"  Stage 1 (Mel only): Epochs 1-{stage2_epoch-1}\")\n",
    "    print(f\"  Stage 2 (Adversarial): Epochs {stage2_epoch}+\")\n",
    "else:\n",
    "    print(f\"  Only Stage 1 active (Mel loss only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa69608",
   "metadata": {},
   "source": [
    "## Section 8: Learning Rate & Convergence Analysis\n",
    "\n",
    "Are you converging to a good solution? This shows if your model is finding better parameters each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30794f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze convergence: how much does mel_loss change epoch to epoch?\n",
    "epoch_mel = df.groupby('epoch')['mel_loss'].mean()\n",
    "epoch_deltas = epoch_mel.diff().dropna()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Epoch-to-epoch changes (deltas)\n",
    "colors_delta = ['green' if x < 0 else 'red' for x in epoch_deltas.values]\n",
    "ax1.bar(epoch_deltas.index, epoch_deltas.values, color=colors_delta, alpha=0.7)\n",
    "ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax1.set_xlabel('Epoch', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Change in Mel Loss', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Epoch-to-Epoch Loss Change\\n(Negative = Improvement)', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: Absolute change magnitude (convergence rate)\n",
    "abs_deltas = epoch_deltas.abs()\n",
    "ax2.plot(abs_deltas.index, abs_deltas.values, marker='o', color='#ff7f0e', linewidth=2, markersize=4)\n",
    "ax2.fill_between(abs_deltas.index, abs_deltas.values, alpha=0.3, color='#ff7f0e')\n",
    "ax2.set_xlabel('Epoch', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('|Change|', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Convergence Rate\\n(Lower = More Stable/Converged)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis\n",
    "print(\"\\nüìâ Convergence Analysis:\\n\")\n",
    "early_changes = epoch_deltas.iloc[:min(20, len(epoch_deltas))].abs()\n",
    "late_changes = epoch_deltas.iloc[max(0, len(epoch_deltas)-20):].abs()\n",
    "\n",
    "print(f\"  Early epochs (first 20) avg change: {early_changes.mean():.6f}\")\n",
    "print(f\"  Recent epochs (last 20) avg change: {late_changes.mean():.6f}\")\n",
    "\n",
    "if late_changes.mean() < early_changes.mean() * 0.5:\n",
    "    print(f\"  ‚úÖ CONVERGING - Changes getting smaller (good sign)\")\n",
    "elif late_changes.mean() < early_changes.mean():\n",
    "    print(f\"  ‚úì SLOWLY CONVERGING - Some improvement\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è  NOT CONVERGING - Changes not decreasing\")\n",
    "    print(f\"     Your model might still be adjusting significantly each epoch\")\n",
    "\n",
    "# Improvement per epoch\n",
    "total_improvement = (epoch_mel.iloc[0] - epoch_mel.iloc[-1]) / len(epoch_mel)\n",
    "print(f\"\\n  Average improvement per epoch: {total_improvement:.6f}\")\n",
    "if total_improvement > 0.001:\n",
    "    print(f\"  ‚úì GOOD - Meaningful progress each epoch\")\n",
    "elif total_improvement > 0:\n",
    "    print(f\"  ‚ö†Ô∏è  SLOW - Very gradual progress\")\n",
    "else:\n",
    "    print(f\"  ‚úó BAD - No net improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf1dbf",
   "metadata": {},
   "source": [
    "## Section 9: Quick Reference Guide\n",
    "\n",
    "### üéØ What to Look For in Your Training\n",
    "\n",
    "| Metric | Good ‚úÖ | Bad ‚ùå |\n",
    "|--------|--------|--------|\n",
    "| **Mel Loss** | Decreases smoothly each epoch | Flat or increasing |\n",
    "| **Loss Curve** | Smooth, consistent | Spiky, erratic jumps |\n",
    "| **Variance** | Low (< 20% noise) | High (> 50% noise) |\n",
    "| **Gen/Disc Loss** | Activates around epoch 20-40 | Stays 0.0 (not training) |\n",
    "| **Stage Transition** | Mel increases slightly, then stabilizes | Mel crashes or diverges |\n",
    "| **Recent Progress** | Still improving (last 20 epochs) | Plateaued for many epochs |\n",
    "\n",
    "### ‚ö° If Training is NOT Going Well...\n",
    "\n",
    "1. **Loss not decreasing?**\n",
    "   - Try reducing learning rate\n",
    "   - Check data preprocessing\n",
    "   - Verify batch size isn't too large\n",
    "\n",
    "2. **Loss is spiky/unstable?**\n",
    "   - Reduce learning rate\n",
    "   - Increase batch size\n",
    "   - Check for NaN in data\n",
    "\n",
    "3. **Losses stuck at 0?**\n",
    "   - Check config file (diff_epoch, joint_epoch parameters)\n",
    "   - Verify training is in the right stage\n",
    "   - Check if losses should be activated yet\n",
    "\n",
    "4. **High variance early, stable later?**\n",
    "   - This is normal! Early epochs are often noisier\n",
    "   - As model converges, losses should smooth out\n",
    "\n",
    "### üìä Running This Monitor\n",
    "\n",
    "- **After each training session**, run this notebook\n",
    "- **Update the LOG_DIR** at the top if monitoring different model\n",
    "- **Track weekly** to spot long-term trends\n",
    "- **Watch for sudden changes** (might indicate config changes or code updates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
