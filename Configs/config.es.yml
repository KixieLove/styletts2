# === logging / runtime ===
log_dir: "logs/angelina_es"          # where to write TB logs & ckpts
first_stage_path: "epoch_1st_00048.pth"  # filename for stage-1 final ckpt
save_freq: 2                         # save every N epochs
log_interval: 10
device: "cuda"

# how long to train (tweak as you like)
epochs_1st: 100                  # stage-1 (pretraining) - start with 200, can increase later
epochs_2nd: 100                      # stage-2 (joint) - start with 100

# batch / length (fits 12GB RTX 4070; adjust if OOM)
batch_size: 8                   # reduced for 12GB GPU stability
max_len: 300                    # reduced to prevent OOM (~15s at 24kHz)

# optional warm-starts (leave empty for fresh training)
pretrained_model: "logs/angelina_es/epoch_2nd_00004.pth"  # resume from epoch 4
second_stage_load_pretrained: true   # set to true to resume stage-2 checkpoint
load_only_params: false             # set to false to load optimizer state too

# === pretrained modules ===
F0_path: "Utils/JDC/bst.t7"          # repo’s F0 (JDC) path
ASR_config: "Utils/ASR/config.yml"
ASR_path:   "Utils/ASR/epoch_00080.pth"
PLBERT_dir: "Utils/PLBERT_all_languages/"  # multilingual PL-BERT for Spanish (note trailing slash)

# === data ===
data_params:
  train_data: "filelists/train.txt"  # we’ll reuse your generated lists
  val_data:   "filelists/val.txt"
  root_path:  ""                     # empty is safest with absolute paths
  OOD_data:   "filelists/ood_es.txt"                     # optional; set later for stage-2
  min_length: 50

# === preprocessing ===
preprocess_params:
  sr: 24000
  spect_params:
    n_fft: 2048
    win_length: 1200
    hop_length: 300
  # n_mels lives under model_params in this repo

# === model ===
model_params:
  multispeaker: false

  dim_in: 64 
  hidden_dim: 512
  max_conv_dim: 512
  n_layer: 3
  n_mels: 80

  n_token: 178          # MUST match ASR model vocab size (178), not symbol count (196)
  max_dur: 50
  style_dim: 128
  dropout: 0.2

  decoder: 
    type: 'istftnet'
    resblock_kernel_sizes: [3,7,11]
    upsample_rates: [10, 6]
    upsample_initial_channel: 512
    resblock_dilation_sizes: [[1,3,5], [1,3,5], [1,3,5]]
    upsample_kernel_sizes: [20, 12]
    gen_istft_n_fft: 20
    gen_istft_hop_size: 5
      
  # speech language model (SLM) discriminator
  slm:
    model: 'microsoft/wavlm-base-plus'
    sr: 16000
    hidden: 768
    nlayers: 13
    initial_channel: 64
  
  # style diffusion config
  diffusion:
    embedding_mask_proba: 0.1
    transformer:
      num_layers: 3
      num_heads: 8
      head_features: 64
      multiplier: 2
    dist:
      sigma_data: 0.2
      estimate_sigma_data: true
      mean: -3.0
      std: 1.0

optimizer_params:
  lr: 0.0001        # main optimizer LR
  bert_lr: 0.00001  # PL-BERT LR
  ft_lr: 0.00001    # fine-tune LR for acoustic modules

# === losses ===
loss_params:
  lambda_mel: 5.
  lambda_gen: 1.
  lambda_slm: 1.
  lambda_mono: 1.
  lambda_s2s: 1.
  TMA_epoch: 50
  lambda_F0: 1.
  lambda_norm: 1.
  lambda_dur: 1.
  lambda_ce: 20.
  lambda_sty: 1.
  lambda_diff: 1.
  diff_epoch: 20
  joint_epoch: 50

# === stage-2 SLM adversarial ===
slmadv_params:
  min_len: 400
  max_len: 500
  batch_percentage: 0.5
  iter: 10
  thresh: 5
  scale: 0.01
  sig: 1.5
